{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f975f7b",
   "metadata": {},
   "source": [
    "# DATA PREPOCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a66f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2a1bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "torch.cuda.set_device(1)\n",
    "device = \"cuda:%s\" % torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91a305",
   "metadata": {},
   "source": [
    "LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ee9377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0                   4               4             NaN              8   \n",
       "1                   5               4             NaN              9   \n",
       "2                   4               3             NaN              7   \n",
       "3                   5               5             NaN             10   \n",
       "4                   4               4             NaN              8   \n",
       "...               ...             ...             ...            ...   \n",
       "12971              17              18             NaN             35   \n",
       "12972              15              17             NaN             32   \n",
       "12973              20              26            40.0             40   \n",
       "12974              20              20             NaN             40   \n",
       "12975              20              20             NaN             40   \n",
       "\n",
       "       rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0                 NaN             NaN            NaN  ...            NaN   \n",
       "1                 NaN             NaN            NaN  ...            NaN   \n",
       "2                 NaN             NaN            NaN  ...            NaN   \n",
       "3                 NaN             NaN            NaN  ...            NaN   \n",
       "4                 NaN             NaN            NaN  ...            NaN   \n",
       "...               ...             ...            ...  ...            ...   \n",
       "12971             NaN             NaN            NaN  ...            4.0   \n",
       "12972             NaN             NaN            NaN  ...            4.0   \n",
       "12973             NaN             NaN            NaN  ...            5.0   \n",
       "12974             NaN             NaN            NaN  ...            4.0   \n",
       "12975             NaN             NaN            NaN  ...            4.0   \n",
       "\n",
       "       rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0                NaN            NaN            NaN            NaN   \n",
       "1                NaN            NaN            NaN            NaN   \n",
       "2                NaN            NaN            NaN            NaN   \n",
       "3                NaN            NaN            NaN            NaN   \n",
       "4                NaN            NaN            NaN            NaN   \n",
       "...              ...            ...            ...            ...   \n",
       "12971            4.0            4.0            3.0            NaN   \n",
       "12972            4.0            4.0            3.0            NaN   \n",
       "12973            5.0            5.0            5.0            4.0   \n",
       "12974            4.0            4.0            4.0            NaN   \n",
       "12975            4.0            4.0            4.0            NaN   \n",
       "\n",
       "       rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
       "0                NaN            NaN            NaN            NaN   \n",
       "1                NaN            NaN            NaN            NaN   \n",
       "2                NaN            NaN            NaN            NaN   \n",
       "3                NaN            NaN            NaN            NaN   \n",
       "4                NaN            NaN            NaN            NaN   \n",
       "...              ...            ...            ...            ...   \n",
       "12971            NaN            NaN            NaN            NaN   \n",
       "12972            NaN            NaN            NaN            NaN   \n",
       "12973            4.0            4.0            4.0            4.0   \n",
       "12974            NaN            NaN            NaN            NaN   \n",
       "12975            NaN            NaN            NaN            NaN   \n",
       "\n",
       "       rater3_trait6  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "...              ...  \n",
       "12971            NaN  \n",
       "12972            NaN  \n",
       "12973            4.0  \n",
       "12974            NaN  \n",
       "12975            NaN  \n",
       "\n",
       "[12976 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset .tsv\n",
    "kaggle_dataset  = pd.read_csv('./training_set_rel3.tsv', sep='\\t', encoding = \"ISO-8859-1\")\n",
    "kaggle_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d4450",
   "metadata": {},
   "source": [
    "DATA CLEANSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc2b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleansing Function\n",
    "def clean_dataset(input_dataset):\n",
    "  # Remove unused column \n",
    "  dataset = pd.DataFrame(\n",
    "    {\n",
    "      'essay_id' : input_dataset['essay_id'],\n",
    "      'essay_set' : input_dataset['essay_set'],\n",
    "      'essay' : input_dataset['essay'],\n",
    "      'score' : input_dataset['domain1_score']\n",
    "    }\n",
    "  )\n",
    "\n",
    "  # Check missing value\n",
    "  missing_values = dataset.isnull().sum()\n",
    "  print(\"Jumlah missing values:\")\n",
    "  print(missing_values)\n",
    "\n",
    "  # Remove missing value\n",
    "  dataset_cleaned = dataset.dropna()\n",
    "  cleaned_missing_values = dataset_cleaned.isnull().sum()\n",
    "  print(\"\\nJumlah missing values setelah data dibersihkan:\")\n",
    "  print(cleaned_missing_values)\n",
    "\n",
    "  print(\"\\nDataset setelah kolom yang tidak dibutuhkan dan nilai kosong dihapus:\")\n",
    "\n",
    "  return dataset_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9858a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing values:\n",
      "essay_id     0\n",
      "essay_set    0\n",
      "essay        0\n",
      "score        0\n",
      "dtype: int64\n",
      "\n",
      "Jumlah missing values setelah data dibersihkan:\n",
      "essay_id     0\n",
      "essay_set    0\n",
      "essay        0\n",
      "score        0\n",
      "dtype: int64\n",
      "\n",
      "Dataset setelah kolom yang tidak dibutuhkan dan nilai kosong dihapus:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       score  \n",
       "0          8  \n",
       "1          9  \n",
       "2          7  \n",
       "3         10  \n",
       "4          8  \n",
       "...      ...  \n",
       "12971     35  \n",
       "12972     32  \n",
       "12973     40  \n",
       "12974     40  \n",
       "12975     40  \n",
       "\n",
       "[12976 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cleaned = clean_dataset(kaggle_dataset)\n",
    "dataset_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa1543",
   "metadata": {},
   "source": [
    "SCORE NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d7572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rentang nilai esai (nilai minimum dan maksimum pada tiap set esai)\n",
    "min_max_ranges = {\n",
    "    1: (2, 12),\n",
    "    2: (1, 6),\n",
    "    3: (0, 3),\n",
    "    4: (0, 3),\n",
    "    5: (0, 4),\n",
    "    6: (0, 4),\n",
    "    7: (0, 30),\n",
    "    8: (0, 60)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8295079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score Normalization Function\n",
    "def normalize_score(dataset, min_max_ranges):\n",
    "\n",
    "    #Rumus min max normalization\n",
    "    def min_max_normalize(score, min_score, max_score):\n",
    "        return (score - min_score) / (max_score - min_score)\n",
    "    \n",
    "    #Normalisasi nilai skor\n",
    "    for essay_set, (min_score, max_score) in min_max_ranges.items():\n",
    "\n",
    "        # Filter dataset berdasarkan essay set\n",
    "        subset = dataset[dataset['essay_set'] == essay_set]\n",
    "        \n",
    "        # Lakukan normalisasi skor secara manual\n",
    "        normalized_scores = subset['score'].apply(lambda x: min_max_normalize(x, min_score, max_score))\n",
    "        \n",
    "        # Update kolom skor pada subset dataset dengan skor yang telah dinormalisasi\n",
    "        dataset.loc[subset.index, 'normalized_score'] = normalized_scores\n",
    "\n",
    "    # Ganti nilai kolom score dengan normalized_score\n",
    "    dataset['score'] = dataset['normalized_score']\n",
    "\n",
    "    # Hapus kolom normalized_score\n",
    "    dataset.drop('normalized_score', axis=1, inplace=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9730276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "0             1          1  Dear local newspaper, I think effects computer...   \n",
       "1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "...         ...        ...                                                ...   \n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "          score  \n",
       "0      0.600000  \n",
       "1      0.700000  \n",
       "2      0.500000  \n",
       "3      0.800000  \n",
       "4      0.600000  \n",
       "...         ...  \n",
       "12971  0.583333  \n",
       "12972  0.533333  \n",
       "12973  0.666667  \n",
       "12974  0.666667  \n",
       "12975  0.666667  \n",
       "\n",
       "[12976 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_normalized = normalize_score(dataset_cleaned, min_max_ranges)\n",
    "dataset_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f782cb",
   "metadata": {},
   "source": [
    "DATA SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af44690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Splitting Function\n",
    "def data_splitting(dataset):\n",
    "    # Dictionary untuk menyimpan data latih dan data uji untuk setiap essay_set\n",
    "    train_data_perset = {}\n",
    "    test_data_perset = {}\n",
    "\n",
    "    # Mendefinisikan essay_set yang tersedia dalam dataset\n",
    "    essay_sets = dataset['essay_set'].unique()\n",
    "\n",
    "    for essay_set in essay_sets:\n",
    "        # Filter dataset berdasarkan essay_set\n",
    "        subset = dataset[dataset_cleaned['essay_set'] == essay_set]\n",
    "        \n",
    "        features = ['essay_id', 'essay_set', 'essay']\n",
    "        X = subset.loc[:, features]\n",
    "        y = subset.loc[:, ['score']]\n",
    "        \n",
    "        # Lakukan splitting menjadi data train (70%) dan data test (30%)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "        \n",
    "        # Menggabungkan X_train dan y_train menjadi dataframe data latih\n",
    "        train_data_perset[essay_set] = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "        # Menggabungkan X_test dan y_test menjadi dataframe data uji\n",
    "        test_data_perset[essay_set] = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    # Menggabungkan semua data train dari setiap essay_set menjadi satu DataFrame data_train\n",
    "    train_data = pd.concat(train_data_perset.values(), ignore_index=True)\n",
    "\n",
    "    # Menggabungkan semua data test dari setiap essay_set menjadi satu DataFrame data_test\n",
    "    test_data = pd.concat(test_data_perset.values(), ignore_index=True)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f15443",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data_splitting(dataset_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e724ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, In my opinion I support ...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, Computers are they a goo...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, @CAPS1 you have a comput...</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 people have computers in t...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1580</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CITY1 @ORGANIZATION1, I am a @ORGANIZATI...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>20806</td>\n",
       "      <td>8</td>\n",
       "      <td>There are a couple things that can lead stran...</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9078</th>\n",
       "      <td>20849</td>\n",
       "      <td>8</td>\n",
       "      <td>In a relationship you should be able to trust...</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>21055</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is a huge part oh building friendshi...</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>21258</td>\n",
       "      <td>8</td>\n",
       "      <td>I think that laughter is a key element to any...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9081</th>\n",
       "      <td>20844</td>\n",
       "      <td>8</td>\n",
       "      <td>I'm a tell you about moments sometimes even a...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9082 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "0         1514          1  Dear Local Newspaper, In my opinion I support ...   \n",
       "1           85          1  Dear local newspaper, Computers are they a goo...   \n",
       "2         1744          1  Dear Local newspaper, @CAPS1 you have a comput...   \n",
       "3         1004          1  Dear @CAPS1, @CAPS2 people have computers in t...   \n",
       "4         1580          1  Dear @CITY1 @ORGANIZATION1, I am a @ORGANIZATI...   \n",
       "...        ...        ...                                                ...   \n",
       "9077     20806          8   There are a couple things that can lead stran...   \n",
       "9078     20849          8   In a relationship you should be able to trust...   \n",
       "9079     21055          8   Laughter is a huge part oh building friendshi...   \n",
       "9080     21258          8   I think that laughter is a key element to any...   \n",
       "9081     20844          8   I'm a tell you about moments sometimes even a...   \n",
       "\n",
       "         score  \n",
       "0     0.600000  \n",
       "1     0.800000  \n",
       "2     0.900000  \n",
       "3     0.400000  \n",
       "4     0.600000  \n",
       "...        ...  \n",
       "9077  0.583333  \n",
       "9078  0.733333  \n",
       "9079  0.583333  \n",
       "9080  0.666667  \n",
       "9081  0.500000  \n",
       "\n",
       "[9082 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cetak data latih\n",
    "print(\"Train Data:\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c2aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>I think computers have a postitive affect on p...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477</td>\n",
       "      <td>1</td>\n",
       "      <td>I blive that computers have a lot of effects o...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>Many people think that computers are not a goo...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper people, @CAPS1 you might heard ...</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>780</td>\n",
       "      <td>1</td>\n",
       "      <td>More and more people are using computers on a ...</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>20920</td>\n",
       "      <td>8</td>\n",
       "      <td>In my storie I am going to tell you about a f...</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>21107</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is an essential component to any rel...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>21514</td>\n",
       "      <td>8</td>\n",
       "      <td>I think laughter should be a huge part in eve...</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>21309</td>\n",
       "      <td>8</td>\n",
       "      <td>Some people say that laughter is the best med...</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>21189</td>\n",
       "      <td>8</td>\n",
       "      <td>Building the @CAPS1 with Laughter @CAPS2 a ve...</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3894 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "0          827          1  I think computers have a postitive affect on p...   \n",
       "1         1477          1  I blive that computers have a lot of effects o...   \n",
       "2          234          1  Many people think that computers are not a goo...   \n",
       "3          801          1  Dear Newspaper people, @CAPS1 you might heard ...   \n",
       "4          780          1  More and more people are using computers on a ...   \n",
       "...        ...        ...                                                ...   \n",
       "3889     20920          8   In my storie I am going to tell you about a f...   \n",
       "3890     21107          8   Laughter is an essential component to any rel...   \n",
       "3891     21514          8   I think laughter should be a huge part in eve...   \n",
       "3892     21309          8   Some people say that laughter is the best med...   \n",
       "3893     21189          8   Building the @CAPS1 with Laughter @CAPS2 a ve...   \n",
       "\n",
       "         score  \n",
       "0     0.400000  \n",
       "1     0.400000  \n",
       "2     0.600000  \n",
       "3     0.700000  \n",
       "4     0.700000  \n",
       "...        ...  \n",
       "3889  0.533333  \n",
       "3890  0.666667  \n",
       "3891  0.566667  \n",
       "3892  0.633333  \n",
       "3893  0.616667  \n",
       "\n",
       "[3894 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cetak data uji\n",
    "print(\"Test Data:\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c311c",
   "metadata": {},
   "source": [
    "# EMBEDDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6144a",
   "metadata": {},
   "source": [
    "Data Loader - Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d3d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat kamus yang memetakan id ke suatu indeks\n",
    "def get_id2emb(ids):\n",
    "\n",
    "  id2emb = {}\n",
    "  for n,id in enumerate(ids.to_list()):\n",
    "    id2emb[id] = n\n",
    "\n",
    "  print('Essay ids to embeddings dictionary created.')\n",
    "  \n",
    "  return id2emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50af486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay ids to embeddings dictionary created.\n",
      "Essay ids to embeddings dictionary created.\n"
     ]
    }
   ],
   "source": [
    "id2emb_train = get_id2emb(train_data['essay_id'])\n",
    "id2emb_test = get_id2emb(test_data['essay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9847c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(df, id2emb, essay_embeddings, batch_size, shuffle):\n",
    "    \n",
    "    # Extract embeddings for each essay_id using the id2emb dictionary\n",
    "    embeddings = np.array([essay_embeddings[id2emb[id]] for id in df['essay_id']])\n",
    "    \n",
    "    # Extract scores from the DataFrame\n",
    "    scores = np.array(df['score'])\n",
    "    \n",
    "    # Create a PyTorch TensorDataset from the embeddings and scores\n",
    "    data = TensorDataset(torch.from_numpy(embeddings).float(), torch.from_numpy(scores).float())\n",
    "    \n",
    "    # Create a PyTorch DataLoader from the TensorDataset\n",
    "    loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, num_workers=2)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe616ca",
   "metadata": {},
   "source": [
    "# EMBEDDING SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6e18b",
   "metadata": {},
   "source": [
    "LOAD PRETRAINED MODEL SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f904e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rifatiad42021/miniconda3/envs/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model information:\n",
      "MPNetModel(\n",
      "  (embeddings): MPNetEmbeddings(\n",
      "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): MPNetEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (relative_attention_bias): Embedding(32, 12)\n",
      "  )\n",
      "  (pooler): MPNetPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Memuat pretrained SBERT dan tokenizer\n",
    "tokenizer_sbert = AutoTokenizer.from_pretrained('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "sbert_model = AutoModel.from_pretrained('sentence-transformers/multi-qa-mpnet-base-dot-v1').to(device)\n",
    "\n",
    "# Mencetak informasi tentang model\n",
    "print(\"Model information:\")\n",
    "print(sbert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c366858",
   "metadata": {},
   "source": [
    "SENTENCE EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf4b4d13-a041-4672-8ed8-4e63160536b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbert_embedding(essay_list, tokenizer, model):\n",
    "\n",
    "    print('Encoding essay embeddings:')\n",
    "\n",
    "    embeddings = []\n",
    "    for essay in tqdm(essay_list):\n",
    "        encoded_input = tokenizer(essay, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "\n",
    "        # Get the token embeddings (excluding the batch dimension)\n",
    "        token_embeddings = model_output.last_hidden_state.squeeze().cpu().numpy()\n",
    "\n",
    "        # Compute mean pooling\n",
    "        mean_pooling = np.mean(token_embeddings, axis=0)\n",
    "\n",
    "        # Compute max pooling\n",
    "        max_pooling = np.max(token_embeddings, axis=0)\n",
    "\n",
    "        # Use the embedding of the CLS token (first token) for each input\n",
    "        cls_pooling = model_output.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "        # Concatenate mean and max pooling results\n",
    "        all_pooling = np.concatenate((mean_pooling, max_pooling, cls_pooling))\n",
    "        \n",
    "        embeddings.append(all_pooling)\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3304de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding essay embeddings:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a4e8b46c724e3d9d401456587ada4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9082 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Menyimpan Embeddings yang dihasilkan SBERT \n",
    "train_embeddings_sbert = sbert_embedding(train_data['essay'], tokenizer_sbert, sbert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee0096a-4465-4d39-8a9a-b5b052d59e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding essay embeddings:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddaa021388d4a8cad3fa908e15f8bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3894 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_embeddings_sbert = sbert_embedding(test_data['essay'], tokenizer_sbert, sbert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98fb41cf-ddc7-4b7a-afd0-ab5428fe29c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9082, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(train_embeddings_sbert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecf55bf4-d57f-43ad-9aed-a788bfcfabce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3894, 2304)\n"
     ]
    }
   ],
   "source": [
    "print(test_embeddings_sbert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "479d4f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09018764, -0.24690011, -0.21070379, ...,  0.14900008,\n",
       "        -0.38313147, -0.12559557],\n",
       "       [-0.07093333, -0.33594415, -0.21142925, ..., -0.21238948,\n",
       "        -0.2107223 , -0.14934623],\n",
       "       [ 0.00704844, -0.3804114 , -0.19440874, ...,  0.01559372,\n",
       "        -0.44941118, -0.3568388 ],\n",
       "       ...,\n",
       "       [ 0.14164513, -0.27081993, -0.22254585, ...,  0.2987161 ,\n",
       "         0.25670302, -0.2111376 ],\n",
       "       [ 0.12121425, -0.38976884, -0.17471671, ...,  0.19508861,\n",
       "         0.18679416, -0.1940057 ],\n",
       "       [ 0.07585978, -0.43111196, -0.22201996, ...,  0.11846084,\n",
       "         0.27284688, -0.23111457]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.shape(train_embeddings_sbert)\n",
    "train_embeddings_sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b60586eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19062395, -0.11745113, -0.25335476, ...,  0.1922959 ,\n",
       "        -0.37625661, -0.30732417],\n",
       "       [-0.08491195, -0.56313676, -0.23268545, ..., -0.18872927,\n",
       "        -0.21885872, -0.49129802],\n",
       "       [ 0.02014007, -0.18596135, -0.16624981, ...,  0.06060598,\n",
       "        -0.01330091, -0.28572068],\n",
       "       ...,\n",
       "       [ 0.10163353, -0.3595566 , -0.1719999 , ...,  0.10730707,\n",
       "         0.2526765 , -0.22698738],\n",
       "       [ 0.12851821, -0.45331287, -0.18497704, ...,  0.21253969,\n",
       "         0.23311758, -0.20888892],\n",
       "       [ 0.02431829, -0.2519529 , -0.24742365, ...,  0.17169283,\n",
       "         0.03229843, -0.13743167]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings_sbert "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29094334",
   "metadata": {},
   "source": [
    "# REGRESI FCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f995c30",
   "metadata": {},
   "source": [
    "INISIALISASI FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "faf3cd82-b670-4994-83b1-08c79be09469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menginisialisasi FCNN\n",
    "class FCNN(nn.Module):\n",
    "    # Fungsi untuk menentukan pengaturan layer\n",
    "    def __init__(self, input_size):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 397)  # Layer pertama: input_size -> 256\n",
    "        self.dropout1 = nn.Dropout(0.3) \n",
    "        self.fc2 = nn.Linear(397, 32)           # Layer kedua: 256 -> 96\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(32, 1)              # Layer ketiga: 96 -> 1\n",
    "        self.sigmoid = nn.Sigmoid()             # Fungsi aktivasi Sigmoid\n",
    "    \n",
    "    # Fungsi untuk untuk melakukan feedforward\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))              # Aktivasi ReLU di layer pertama\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))              # Aktivasi ReLU di layer kedua\n",
    "        x = self.dropout2(x) \n",
    "        x = self.fc3(x)                                     # Layer ketiga (output layer)\n",
    "        return self.sigmoid(x)                        # Output dengan fungsi aktivasi Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11c3e1",
   "metadata": {},
   "source": [
    "TESTING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1dc4d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(trained_model, cost_function, test_loader):\n",
    "    trained_model.eval() # Mengatur model ke mode evaluasi (eval mode)\n",
    "    test_loss = 0.\n",
    "    samples = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (inputs, targets) in enumerate(test_loader):\n",
    "            \n",
    "            # Menghapus dimensi yang tidak perlu dari inputs dan mentransfer ke device\n",
    "            inputs = inputs.squeeze(dim=1).to(device)\n",
    "            \n",
    "            # Menyesuaikan dimensi targets dan mentransfer ke device\n",
    "            targets = targets.reshape(targets.shape[0], 1).to(device)\n",
    "            \n",
    "            # Menghitung output model (prediksi) dari inputs\n",
    "            outputs = trained_model(inputs).reshape(-1, 1)\n",
    "            \n",
    "            # Menghitung nilai loss dengan membandingkan outputs dengan targets\n",
    "            loss = cost_function(outputs, targets)\n",
    "            \n",
    "            # Menghitung jumlah sampel dalam batch\n",
    "            samples += inputs.shape[0]\n",
    "            \n",
    "            # Menambahkan nilai loss dari batch ke test_loss\n",
    "            test_loss += loss.item() * inputs.shape[0]\n",
    "            \n",
    "    # Menghitung rata-rata loss di seluruh batch (samples)\n",
    "    avg_loss = test_loss / samples\n",
    "    \n",
    "    # Mengembalikan nilai rata-rata loss\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72e3c7",
   "metadata": {},
   "source": [
    "TRAINING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "105c5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh fungsi untuk training model\n",
    "def training_step(model, cost_function, train_loader, test_loader, save_path, num_epochs, lr):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Mengatur model ke mode pelatihan\n",
    "        \n",
    "        # Mengatur gradien parameter ke nilai nol untuk iterasi\n",
    "        running_loss = 0.\n",
    "        samples = 0.\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            \n",
    "            # Menghapus dimensi yang tidak perlu dari inputs dan mentransfer ke device\n",
    "            inputs = inputs.to(device)\n",
    "        \n",
    "            # Menyesuaikan dimensi targets dan mentransfer ke device\n",
    "            targets = targets.reshape(targets.shape[0], 1).to(device)\n",
    "            \n",
    "            # Menghitung output model (prediksi) dari inputs\n",
    "            outputs = model(inputs).reshape(-1, 1)\n",
    "            \n",
    "            # Menghitung nilai loss dengan membandingkan outputs dengan targets\n",
    "            loss = cost_function(outputs, targets)\n",
    "\n",
    "            # Mengatur gradien parameter ke nilai nol untuk iterasi berikutnya\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Melakukan backpropagation untuk menghitung gradien loss terhadap parameter model\n",
    "            loss.backward()\n",
    "            \n",
    "            # Melakukan optimizer untuk mengupdate parameter model berdasarkan gradien\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Menambahkan nilai loss dari batch ke running_loss\n",
    "            running_loss += loss.item() * inputs.shape[0]\n",
    "            \n",
    "            # Menghitung jumlah sampel dalam batch\n",
    "            samples += inputs.shape[0]\n",
    "        \n",
    "        # Menghitung rata-rata loss pada data latih\n",
    "        train_loss = running_loss / samples\n",
    "        \n",
    "         # Evaluasi pada data uji\n",
    "        test_loss = test_step(model, cost_function, test_loader)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print('Epoch: {:}/{:}\\tLoss/train: {:.5f}\\tLoss/test: {:.5f}'.format(epoch+1, num_epochs, train_loss, test_loss))\n",
    "    \n",
    "    # Simpan model setelah pelatihan\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved at {save_path}\")\n",
    "    \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f44aae7",
   "metadata": {},
   "source": [
    "SCORING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b02d6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi untuk melakukan prediksi pada data uji\n",
    "def scoring(trained_model, test_loader):\n",
    "    trained_model.to(device)  # Move the model to the correct device\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            # Lakukan prediksi dengan model yang telah dilatih\n",
    "            outputs = trained_model(inputs)\n",
    "            \n",
    "            # Menyimpan prediksi (outputs) dalam bentuk list predictions\n",
    "            predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf218006",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36da919b-309a-4e92-ae31-e89cfbe0cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e9831-1d61-4cd1-a27d-1092768abd13",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8c309f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "\t\t\tTraining model SBERT: \n",
      "------------------------------------------------------------------\n",
      "Epoch: 1/8\tLoss/train: 0.04096\tLoss/test: 0.02752\n",
      "Epoch: 2/8\tLoss/train: 0.02769\tLoss/test: 0.02307\n",
      "Epoch: 3/8\tLoss/train: 0.02418\tLoss/test: 0.02173\n",
      "Epoch: 4/8\tLoss/train: 0.02266\tLoss/test: 0.02098\n",
      "Epoch: 5/8\tLoss/train: 0.02181\tLoss/test: 0.02162\n",
      "Epoch: 6/8\tLoss/train: 0.02109\tLoss/test: 0.01986\n",
      "Epoch: 7/8\tLoss/train: 0.02079\tLoss/test: 0.02036\n",
      "Epoch: 8/8\tLoss/train: 0.02029\tLoss/test: 0.02040\n",
      "Model saved at model_sbert_v7-mean_max_cls_4.4.pth\n",
      "Training time: 20.15289807319641\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter\n",
    "input_size = 2304\n",
    "batch_size = 16\n",
    "lr = 3e-5\n",
    "epochs = 8\n",
    "\n",
    "# TRAINING\n",
    "# Inisialisasi model, loader, dan fungsi loss\n",
    "model_sbert = FCNN(input_size).to(device)  # Ganti dengan model Anda\n",
    "cost_function = torch.nn.MSELoss()\n",
    "\n",
    "# Dataloaders\n",
    "train_loader_sbert = get_loader(train_data, id2emb_train, train_embeddings_sbert, batch_size, shuffle=True)\n",
    "test_loader_sbert = get_loader(test_data, id2emb_test, test_embeddings_sbert, batch_size, shuffle=False)\n",
    "\n",
    "print('------------------------------------------------------------------')\n",
    "print(f\"\\t\\t\\tTraining model SBERT: \")\n",
    "print('------------------------------------------------------------------')\n",
    "# Path tempat model akan disimpan dan dimuat\n",
    "save_path = 'model_sbert_v7-mean_max_cls_4.4.pth'\n",
    "\n",
    "start_time_sbert = time.time()\n",
    "train_loss_sbert, test_loss_sbert = training_step(model_sbert, cost_function, train_loader_sbert, test_loader_sbert, save_path, epochs, lr)\n",
    "end_time_sbert = time.time()\n",
    "\n",
    "print('Training time:', end_time_sbert - start_time_sbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d2851-6ab7-43a9-9129-b6088f631130",
   "metadata": {},
   "source": [
    "SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "608de217-f7e9-444e-a014-ed3a94ba22a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "\t\t\tScoring Essay: \n",
      "------------------------------------------------------------------\n",
      "Evaluation time: 0.504833459854126\n"
     ]
    }
   ],
   "source": [
    "# Memuat model yang telah dilatih\n",
    "model_sbert_trained = model_sbert \n",
    "model_sbert_trained.load_state_dict(torch.load(save_path))\n",
    "\n",
    "# Menggunakan model untuk prediksi pada data uji\n",
    "print('------------------------------------------------------------------')\n",
    "print(f\"\\t\\t\\tScoring Essay: \")\n",
    "print('------------------------------------------------------------------')\n",
    "start_time_eval = time.time()\n",
    "test_predictions_sbert = scoring(model_sbert_trained, test_loader_sbert)\n",
    "end_time_eval = time.time()\n",
    "print('Evaluation time:', end_time_eval - start_time_eval)\n",
    "\n",
    "# store train_df, test_df and predictions\n",
    "train_df_sbert = train_data\n",
    "test_df_sbert = test_data\n",
    "preds_sbert = test_predictions_sbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa091b",
   "metadata": {},
   "source": [
    "# RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b5f98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(test_df, model_preds):\n",
    "\n",
    "  # create new results df with model scaled preds\n",
    "  preds_df = pd.DataFrame(model_preds)\n",
    "  results_df = test_df.reset_index(drop=True)\\\n",
    "              .join(preds_df)\\\n",
    "              .rename(columns={0:'prediction'})\\\n",
    "              .sort_values(by='essay_id')\\\n",
    "              .reset_index(drop=True)\n",
    "\n",
    "  # move score to last colum\n",
    "  s_df = results_df.pop('score')\n",
    "  results_df['score'] = s_df\n",
    "\n",
    "  return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87715126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, The computer blinked to l...</td>\n",
       "      <td>0.811038</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I've heard that not many...</td>\n",
       "      <td>0.808737</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper People, I think that computers ...</td>\n",
       "      <td>0.688999</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>I agree that computers deffinately are an adva...</td>\n",
       "      <td>0.783868</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @ORGANIZATION1 I think the effects that ...</td>\n",
       "      <td>0.521431</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>21613</td>\n",
       "      <td>8</td>\n",
       "      <td>Before my best friend moved away, we would st...</td>\n",
       "      <td>0.643766</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>21615</td>\n",
       "      <td>8</td>\n",
       "      <td>@ORGANIZATION1  ...</td>\n",
       "      <td>0.605741</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>0.774920</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>0.670974</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3894 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "0           16          1  Dear @ORGANIZATION1, The computer blinked to l...   \n",
       "1           24          1  Dear local newspaper, I've heard that not many...   \n",
       "2           30          1  Dear Newspaper People, I think that computers ...   \n",
       "3           31          1  I agree that computers deffinately are an adva...   \n",
       "4           33          1  Dear, @ORGANIZATION1 I think the effects that ...   \n",
       "...        ...        ...                                                ...   \n",
       "3889     21613          8   Before my best friend moved away, we would st...   \n",
       "3890     21615          8                                @ORGANIZATION1  ...   \n",
       "3891     21626          8   In most stories mothers and daughters are eit...   \n",
       "3892     21628          8   I never understood the meaning laughter is th...   \n",
       "3893     21630          8                                 Trippin' on fen...   \n",
       "\n",
       "      prediction     score  \n",
       "0       0.811038  1.000000  \n",
       "1       0.808737  0.900000  \n",
       "2       0.688999  0.600000  \n",
       "3       0.783868  0.800000  \n",
       "4       0.521431  0.400000  \n",
       "...          ...       ...  \n",
       "3889    0.643766  0.666667  \n",
       "3890    0.605741  0.533333  \n",
       "3891    0.774920  0.583333  \n",
       "3892    0.670974  0.533333  \n",
       "3893    0.639566  0.666667  \n",
       "\n",
       "[3894 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_df(test_df_sbert, preds_sbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce84069",
   "metadata": {},
   "source": [
    "# DENORMALISASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78d1d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize_score(score, min_max_range):\n",
    "    # Mendapatkan nilai minimum dan maksimum dari rentang normalisasi\n",
    "    min_score, max_score = min_max_range\n",
    "    \n",
    "    # Mengembalikan skor esai yang sudah dinormalisasi ke rentang aslinya\n",
    "    return round(score * (max_score - min_score) + min_score)\n",
    "\n",
    "def restore_original_scores(df, preds, min_max_ranges):\n",
    "    # Membuat salinan dataframe untuk menghindari modifikasi dataframe asli\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Mendapatkan kolom skor aktual\n",
    "    actual_scores = df_copy['score'].values\n",
    "    \n",
    "    # Mendapatkan kolom essay_set\n",
    "    essay_sets = df_copy['essay_set'].values\n",
    "    \n",
    "    # Memastikan preds memiliki panjang yang sama dengan jumlah data\n",
    "    assert len(preds) == len(df_copy), \"Length of predictions does not match length of dataframe\"\n",
    "    \n",
    "    # Memulihkan skor prediksi dan skor aktual ke rentang aslinya\n",
    "    restored_preds = [inverse_normalize_score(pred, min_max_ranges[essay_set]) for pred, essay_set in zip(preds, essay_sets)]\n",
    "    restored_actuals = [inverse_normalize_score(actual, min_max_ranges[essay_set]) for actual, essay_set in zip(actual_scores, essay_sets)]\n",
    "    \n",
    "    # Mengganti kolom skor prediksi dan aktual dengan skor yang sudah dipulihkan\n",
    "    df_copy['prediction'] = restored_preds\n",
    "    df_copy['score'] = restored_actuals\n",
    "    \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72dd7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>I think computers have a postitive affect on p...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477</td>\n",
       "      <td>1</td>\n",
       "      <td>I blive that computers have a lot of effects o...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>Many people think that computers are not a goo...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper people, @CAPS1 you might heard ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>780</td>\n",
       "      <td>1</td>\n",
       "      <td>More and more people are using computers on a ...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>20920</td>\n",
       "      <td>8</td>\n",
       "      <td>In my storie I am going to tell you about a f...</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>21107</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is an essential component to any rel...</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>21514</td>\n",
       "      <td>8</td>\n",
       "      <td>I think laughter should be a huge part in eve...</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>21309</td>\n",
       "      <td>8</td>\n",
       "      <td>Some people say that laughter is the best med...</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>21189</td>\n",
       "      <td>8</td>\n",
       "      <td>Building the @CAPS1 with Laughter @CAPS2 a ve...</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3894 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "0          827          1  I think computers have a postitive affect on p...   \n",
       "1         1477          1  I blive that computers have a lot of effects o...   \n",
       "2          234          1  Many people think that computers are not a goo...   \n",
       "3          801          1  Dear Newspaper people, @CAPS1 you might heard ...   \n",
       "4          780          1  More and more people are using computers on a ...   \n",
       "...        ...        ...                                                ...   \n",
       "3889     20920          8   In my storie I am going to tell you about a f...   \n",
       "3890     21107          8   Laughter is an essential component to any rel...   \n",
       "3891     21514          8   I think laughter should be a huge part in eve...   \n",
       "3892     21309          8   Some people say that laughter is the best med...   \n",
       "3893     21189          8   Building the @CAPS1 with Laughter @CAPS2 a ve...   \n",
       "\n",
       "      score  prediction  \n",
       "0         6           7  \n",
       "1         6           6  \n",
       "2         8           9  \n",
       "3         9           9  \n",
       "4         9          10  \n",
       "...     ...         ...  \n",
       "3889     32          36  \n",
       "3890     40          45  \n",
       "3891     34          37  \n",
       "3892     38          40  \n",
       "3893     37          40  \n",
       "\n",
       "[3894 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengembalikan skor prediksi dan skor aktual ke rentang awalnya\n",
    "restored_results_df_sbert = restore_original_scores(test_df_sbert, preds_sbert, min_max_ranges)\n",
    "\n",
    "# Cetak hasilnya\n",
    "print(\"Restored Results:\")\n",
    "restored_results_df_sbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144dadc",
   "metadata": {},
   "source": [
    "# EVALUASI QWK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0640c52c-d4a5-4cd8-9f09-1231b01e6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_qwk(actuals, preds):\n",
    "    # Menentukan nilai minimum dan maksimum untuk rentang skor\n",
    "    min_rating = min(min(actuals), min(preds))\n",
    "    max_rating = max(max(actuals), max(preds))\n",
    "    \n",
    "    # Jumlah total kemungkinan penilaian\n",
    "    num_ratings = max_rating - min_rating + 1\n",
    "\n",
    "    # Membuat matriks bobot W\n",
    "    weight_mat = np.zeros((num_ratings, num_ratings))\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            weight_mat[i][j] = ((i - j) ** 2) / ((num_ratings - 1) ** 2)\n",
    "\n",
    "    # Membuat matriks observasi O\n",
    "    conf_mat = np.zeros((num_ratings, num_ratings))\n",
    "    for actual, pred in zip(actuals, preds):\n",
    "        conf_mat[actual - min_rating][pred - min_rating] += 1\n",
    "\n",
    "    # Membuat matriks ekspektasi E\n",
    "    actual_hist = np.zeros(num_ratings)\n",
    "    pred_hist = np.zeros(num_ratings)\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            actual_hist[i] += conf_mat[i][j]\n",
    "            pred_hist[j] += conf_mat[i][j]\n",
    "\n",
    "    expected_mat = np.outer(actual_hist, pred_hist) / len(actuals)\n",
    "\n",
    "    # Menghitung nilai QWK\n",
    "    num_agreements = np.sum(weight_mat * conf_mat)\n",
    "    num_possible_agreements = np.sum(weight_mat * expected_mat)\n",
    "    kappa_score = 1 - (num_agreements / num_possible_agreements)\n",
    "\n",
    "    return kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3443356b-4b36-4618-b361-924b045088a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung QWK per set\n",
    "def calculate_qwk_per_set(df):\n",
    "    # Menyimpan nilai QWK per set dalam dictionary\n",
    "    qwk_per_set = {}\n",
    "    \n",
    "    # Mendapatkan unique essay_set values\n",
    "    essay_sets = df['essay_set'].unique()\n",
    "    \n",
    "    # Iterasi melalui setiap essay_set\n",
    "    for essay_set in essay_sets:\n",
    "        # Filter dataframe berdasarkan essay_set\n",
    "        subset_df = df[df['essay_set'] == essay_set]\n",
    "        \n",
    "        # Mengekstrak skor aktual dan prediksi dari subset dataframe\n",
    "        actual_scores = subset_df['score'].astype(int)\n",
    "        predicted_scores = subset_df['prediction'].astype(int)\n",
    "        \n",
    "        # Menghitung QWK untuk subset tersebut\n",
    "        qwk = calculate_qwk(actual_scores, predicted_scores)\n",
    "        \n",
    "        # Menyimpan nilai QWK ke dalam dictionary\n",
    "        qwk_per_set[f'Set {essay_set}'] = qwk\n",
    "    \n",
    "    return qwk_per_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "695d8cda-6896-4180-a9a3-fa9fc45647ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Weighted Kappa Score for Set 1: 0.6648262593519234\n",
      "Quadratic Weighted Kappa Score for Set 2: 0.6142555190230155\n",
      "Quadratic Weighted Kappa Score for Set 3: 0.5967211887562227\n",
      "Quadratic Weighted Kappa Score for Set 4: 0.7106733680128814\n",
      "Quadratic Weighted Kappa Score for Set 5: 0.7074610551799208\n",
      "Quadratic Weighted Kappa Score for Set 6: 0.699178428481146\n",
      "Quadratic Weighted Kappa Score for Set 7: 0.7810318627140574\n",
      "Quadratic Weighted Kappa Score for Set 8: 0.46990522789369604\n",
      "Average Quadratic Weighted Kappa Score: 0.6555066136766079\n"
     ]
    }
   ],
   "source": [
    "# Menghitung QWK per set\n",
    "qwk_per_set_sbert = calculate_qwk_per_set(restored_results_df_sbert)\n",
    "\n",
    "# Menampilkan nilai QWK per set\n",
    "for essay_set, qwk_score in qwk_per_set_sbert.items():\n",
    "    print(f\"Quadratic Weighted Kappa Score for {essay_set}: {qwk_score}\")\n",
    "\n",
    "# Menghitung rata-rata nilai QWK dari semua set\n",
    "average_qwk_sbert = np.mean(list(qwk_per_set_sbert.values()))\n",
    "\n",
    "# Menampilkan rata-rata nilai QWK\n",
    "print(\"Average Quadratic Weighted Kappa Score:\", average_qwk_sbert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv] *",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
